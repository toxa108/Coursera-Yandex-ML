{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/toxa/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/toxa/anaconda3/lib/python3.6/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 ... 8 9 8]\n",
      "(1797,)\n",
      "[[ 0.  0.  5. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ... 10.  0.  0.]\n",
      " [ 0.  0.  0. ... 16.  9.  0.]\n",
      " ...\n",
      " [ 0.  0.  1. ...  6.  0.  0.]\n",
      " [ 0.  0.  2. ... 12.  0.  0.]\n",
      " [ 0.  0. 10. ... 12.  1.  0.]]\n",
      "(1797, 64)\n",
      "0.8313915723972958\n"
     ]
    }
   ],
   "source": [
    "from sklearn import cross_validation, model_selection, datasets, grid_search, linear_model, metrics, tree \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def write_answer_1(auc):\n",
    "    with open(\"answer1.txt\", \"w\") as fout:\n",
    "        fout.write(str(auc))\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "print (digits.target)\n",
    "print (digits.target.shape)\n",
    "\n",
    "print (digits.data)\n",
    "print (digits.data.shape)\n",
    "\n",
    "score = model_selection.cross_val_score(tree.DecisionTreeClassifier(), digits.data, digits.target, cv=10)\n",
    "print (score.mean())\n",
    "write_answer_1(score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9210413262369856\n"
     ]
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "\n",
    "def write_answer_2(auc):\n",
    "    with open(\"answer2.txt\", \"w\") as fout:\n",
    "        fout.write(str(auc))\n",
    "\n",
    "score = model_selection.cross_val_score(ensemble.BaggingClassifier(n_estimators=100), digits.data, digits.target, cv=10, n_jobs=4)\n",
    "print (score.mean())\n",
    "write_answer_2(score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "8\n",
      "0.9365149897521154\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "\n",
    "def write_answer_3(auc):\n",
    "    with open(\"answer3.txt\", \"w\") as fout:\n",
    "        fout.write(str(auc))\n",
    "\n",
    "d = int(sqrt(digits.data.shape[1]))\n",
    "print (digits.data.shape[1])\n",
    "print (d)\n",
    "\n",
    "score = model_selection.cross_val_score(ensemble.BaggingClassifier(n_estimators=100, max_features=d), digits.data, digits.target, cv=10, n_jobs=4)\n",
    "print (score.mean())\n",
    "write_answer_3(score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9527147008393066\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "\n",
    "def write_answer_4(auc):\n",
    "    with open(\"answer4.txt\", \"w\") as fout:\n",
    "        fout.write(str(auc))\n",
    "\n",
    "def score_bagging_custom(max_feat, deep, estimators):\n",
    "    return model_selection.cross_val_score(ensemble.BaggingClassifier(n_estimators=estimators, base_estimator=tree.DecisionTreeClassifier(max_features=d, max_depth=deep)), digits.data, digits.target, cv=10)\n",
    "\n",
    "d = int(sqrt(digits.data.shape[1]))\n",
    "score = score_bagging_custom(d, 10, 100)\n",
    "\n",
    "print (score.mean())\n",
    "write_answer_4(score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9461111593665988\n"
     ]
    }
   ],
   "source": [
    "def write_answer_5(auc):\n",
    "    with open(\"answer5.txt\", \"w\") as fout:\n",
    "        fout.write(str(auc))\n",
    "        \n",
    "def score_random_forest(max_feat, deep, estimators):\n",
    "    return model_selection.cross_val_score(ensemble.RandomForestClassifier(n_estimators=estimators, max_features=max_feat, max_depth=deep), digits.data, digits.target, cv=10)\n",
    "\n",
    "d = int(sqrt(digits.data.shape[1]))\n",
    "score = score_random_forest(d, 10, 100)\n",
    "print (score.mean())\n",
    "write_answer_5(score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deep - 200, n_estimators - 1, max_features - 5, random Forest - 0.7144315253887876, Baggin - 0\n",
      "deep - 200, n_estimators - 10, max_features - 5, random Forest - 0.9115250352769259, Baggin - 0\n",
      "deep - 200, n_estimators - 30, max_features - 5, random Forest - 0.9461291395541458, Baggin - 0\n",
      "deep - 200, n_estimators - 40, max_features - 5, random Forest - 0.9467092135039626, Baggin - 0\n",
      "deep - 200, n_estimators - 50, max_features - 5, random Forest - 0.9517078528908762, Baggin - 0\n",
      "deep - 200, n_estimators - 60, max_features - 5, random Forest - 0.9527431076765838, Baggin - 0\n",
      "deep - 200, n_estimators - 70, max_features - 5, random Forest - 0.9511823180752957, Baggin - 0\n",
      "deep - 200, n_estimators - 80, max_features - 5, random Forest - 0.9555462338984514, Baggin - 0\n",
      "deep - 200, n_estimators - 100, max_features - 5, random Forest - 0.948349984884838, Baggin - 0\n"
     ]
    }
   ],
   "source": [
    "deep = [200]\n",
    "estimators = [1, 10, 30, 40, 50, 60, 70, 80, 100]\n",
    "max_features = [5]\n",
    "\n",
    "for d in range(len(deep)):\n",
    "    for e in range(len(estimators)):\n",
    "        for f in range(len(max_features)):\n",
    "            forest = score_random_forest(max_features[f], deep[d], estimators[e]).mean()\n",
    "#             bagging = score_bagging_custom(max_features[f], deep[d], estimators[e]).mean()\n",
    "            res = \"deep - \" + str(deep[d]) + \", n_estimators - \" + str(estimators[e]) + \", max_features - \" + str(max_features[f]) + \", random Forest - \" + str(forest) + \", Baggin - 0\";  \n",
    "            print (res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
